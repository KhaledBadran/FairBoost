{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from aif360.datasets import GermanDataset\n",
    "from aif360.algorithms.preprocessing import Reweighing, OptimPreproc, LFR, DisparateImpactRemover\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.opt_tools import OptTools\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.distortion_functions  import get_distortion_german, get_distortion_adult\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_german, load_preproc_data_adult\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "\n",
    "from FairBoost import FairBoost, Bootstrap_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ipdb\n",
    "import  ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zz5SYmWMlLCu",
    "outputId": "22e31342-9080-4231-8faa-40786143316f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "%pdb off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_orig = load_preproc_data_adult()\n",
    "dataset_orig_train, dataset_orig_test = dataset_orig.split([0.7], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Privileged and unprivileged groups specified will not be used. The protected attributes are directly specified in the data preprocessing function. The current implementation automatically adjusts for discrimination across all groups. This can be changed by changing the optimization code.\n"
     ]
    }
   ],
   "source": [
    "optim_options = {\n",
    "    \"distortion_fun\": get_distortion_adult,\n",
    "    \"epsilon\": 0.05,\n",
    "    \"clist\": [0.99, 1.99, 2.99],\n",
    "    \"dlist\": [.1, 0.05, 0] \n",
    "    }   \n",
    "\n",
    "\n",
    "privileged_groups = [{'sex': 1.0}]\n",
    "unprivileged_groups = [{'sex': 0.0}]\n",
    "pp2 = OptimPreproc(OptTools, optim_options,\n",
    "                  unprivileged_groups = unprivileged_groups,\n",
    "                  privileged_groups = privileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## TODO: Fairboost does not support Reweighing!!\n",
    "pp1 = Reweighing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp3 = LFR(unprivileged_groups=unprivileged_groups,\n",
    "         privileged_groups=privileged_groups,\n",
    "         k=10, Ax=0.1, Ay=1.0, Az=2.0,\n",
    "         verbose=1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp4 = DisparateImpactRemover(repair_level=.5)\n",
    "pp4.transform = pp4.fit_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = (pp1,pp2,pp4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reweighing\n",
      "OptimPreproc\n",
      "DisparateImpactRemover\n",
      "(34189, 18), (34189, 1), (34189, 1)\n",
      "(34189, 18), (34189, 1), (34189, 1)\n",
      "(34189, 18), (34189, 1), (34189, 1)\n",
      "Reweighing\n",
      "OptimPreproc\n",
      "DisparateImpactRemover\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8031802361291203"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "\n",
    "ens = FairBoost(model, pp, bootstrap_type=Bootstrap_type.DEFAULT)\n",
    "ens = ens.fit(dataset_orig_train)\n",
    "y_pred = ens.predict(dataset_orig_test)\n",
    "accuracy_score(y_pred, dataset_orig_test.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8041356718760664"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model = model.fit(dataset_orig_train.features, dataset_orig_train.labels.ravel())\n",
    "y_pred = model.predict(dataset_orig_test.features)\n",
    "accuracy_score(y_pred, dataset_orig_test.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8014741008667167"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp_ = DisparateImpactRemover(repair_level=1)\n",
    "dataset_orig_train_m = pp_.fit_transform(dataset_orig_train)\n",
    "y = deepcopy(dataset_orig_test.labels)\n",
    "dataset_orig_test_m = pp_.fit_transform(dataset_orig_test)\n",
    "model = LogisticRegression()\n",
    "model = model.fit(dataset_orig_train_m.features, dataset_orig_train_m.labels.ravel())\n",
    "y_pred = model.predict(dataset_orig_test_m.features)\n",
    "accuracy_score(y_pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dataset_orig_test.labels == y).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_orig_test.labels is y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPTIM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Privileged and unprivileged groups specified will not be used. The protected attributes are directly specified in the data preprocessing function. The current implementation automatically adjusts for discrimination across all groups. This can be changed by changing the optimization code.\n",
      "\n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "This code path has been hit 21 times so far.\n",
      "\n",
      "\n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "This code path has been hit 22 times so far.\n",
      "\n",
      "\n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "This code path has been hit 23 times so far.\n",
      "\n",
      "\n",
      "This use of ``*`` has resulted in matrix multiplication.\n",
      "Using ``*`` for matrix multiplication has been deprecated since CVXPY 1.1.\n",
      "    Use ``*`` for matrix-scalar and vector-scalar multiplication.\n",
      "    Use ``@`` for matrix-matrix and matrix-vector multiplication.\n",
      "    Use ``multiply`` for elementwise multiplication.\n",
      "This code path has been hit 24 times so far.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7928069337337064"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim_options = {\n",
    "    \"distortion_fun\": get_distortion_adult,\n",
    "    \"epsilon\": 0.05,\n",
    "    \"clist\": [0.99, 1.99, 2.99],\n",
    "    \"dlist\": [.1, 0.05, 0] \n",
    "    }   \n",
    "\n",
    "\n",
    "privileged_groups = [{'sex': 1.0}]\n",
    "unprivileged_groups = [{'sex': 0.0}]\n",
    "pp_ = OptimPreproc(OptTools, optim_options,\n",
    "                  unprivileged_groups = unprivileged_groups,\n",
    "                  privileged_groups = privileged_groups)\n",
    "\n",
    "dataset_orig_train_m = pp_.fit_transform(dataset_orig_train)\n",
    "y = deepcopy(dataset_orig_test.labels)\n",
    "dataset_orig_test_m = pp_.transform(dataset_orig_test)\n",
    "model = LogisticRegression()\n",
    "model = model.fit(dataset_orig_train_m.features, dataset_orig_train_m.labels.ravel())\n",
    "y_pred = model.predict(dataset_orig_test_m.features)\n",
    "accuracy_score(y_pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((dataset_orig_test.labels == y).all())\n",
    "print(dataset_orig_test.labels is y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: 0.8979977405808632, L_x: 0.5146691135723371,  L_y: 0.8261957803771842,  L_z: 0.010167524423222666\n",
      "step: 250, loss: 0.7154116975733398, L_x: 0.5136321847105362,  L_y: 0.6444896083516051,  L_z: 0.009779435375340522\n",
      "step: 500, loss: 0.6260708559143251, L_x: 0.5086164425080072,  L_y: 0.5577051214516938,  L_z: 0.008752045105915275\n",
      "step: 750, loss: 0.6144027227772167, L_x: 0.5027025394672887,  L_y: 0.5490162492231774,  L_z: 0.007558109803655221\n",
      "step: 1000, loss: 0.6048071116585004, L_x: 0.48236644135739387,  L_y: 0.54600181770085,  L_z: 0.005284324910955532\n",
      "step: 1250, loss: 0.5917195492667402, L_x: 0.4554178623806014,  L_y: 0.536531519369358,  L_z: 0.004823121829661031\n",
      "step: 1500, loss: 0.5829306019709901, L_x: 0.38684488350261836,  L_y: 0.5257616473260712,  L_z: 0.009242233147328503\n",
      "step: 1750, loss: 0.5571488066201193, L_x: 0.3503511417119411,  L_y: 0.4974340117509254,  L_z: 0.012339840348999917\n",
      "step: 2000, loss: 0.5475890690464027, L_x: 0.3337642112794511,  L_y: 0.4915058931723104,  L_z: 0.011353377373073561\n",
      "step: 2250, loss: 0.5390043982546224, L_x: 0.30361117179604885,  L_y: 0.4894152048517987,  L_z: 0.009614038111609435\n",
      "step: 2500, loss: 0.5286279755855139, L_x: 0.27231778435038606,  L_y: 0.4862407721169364,  L_z: 0.007577712516769429\n",
      "step: 2750, loss: 0.5252796944954766, L_x: 0.2605699702558131,  L_y: 0.48813980472581747,  L_z: 0.005541446372038886\n",
      "step: 3000, loss: 0.5219498264326111, L_x: 0.25787183544612213,  L_y: 0.48939709215214056,  L_z: 0.003382775367929194\n",
      "step: 3250, loss: 0.5182094303965598, L_x: 0.2600717476393173,  L_y: 0.4868442780278208,  L_z: 0.002678988802403578\n",
      "step: 3500, loss: 0.5166666373229987, L_x: 0.2569280764077113,  L_y: 0.48569796724042225,  L_z: 0.0026379312209026647\n",
      "step: 3750, loss: 0.516400545091454, L_x: 0.24887919524295585,  L_y: 0.48387199997575175,  L_z: 0.0038203127957033038\n",
      "step: 4000, loss: 0.5148017412818116, L_x: 0.24570141714817506,  L_y: 0.48258462688356324,  L_z: 0.0038234863417153943\n",
      "step: 4250, loss: 0.5123944383368992, L_x: 0.22549546093403333,  L_y: 0.47918470598804747,  L_z: 0.005330093127724197\n",
      "step: 4500, loss: 0.5097775800491118, L_x: 0.2281214655560867,  L_y: 0.47790952777323725,  L_z: 0.004527952860132886\n",
      "step: 4750, loss: 0.5078794824577153, L_x: 0.22981685226488113,  L_y: 0.47818176663183193,  L_z: 0.003358015299697631\n",
      "step: 5000, loss: 0.5054773338990037, L_x: 0.21670261488279047,  L_y: 0.4786697786778133,  L_z: 0.00256864686645568\n",
      "step: 5250, loss: 0.50404985883949, L_x: 0.22071594971083766,  L_y: 0.4778100829649253,  L_z: 0.0020840904517405016\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30844/674013262.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdataset_orig_test_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpp_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_orig_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_orig_train_m\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_orig_train_m\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_orig_test_m\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m             raise ValueError(\"This solver needs samples of at least 2 classes\"\n\u001b[0m\u001b[1;32m   1375\u001b[0m                              \u001b[0;34m\" in the data, but the data contains only one\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m                              \" class: %r\" % classes_[0])\n",
      "\u001b[0;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0.0"
     ]
    }
   ],
   "source": [
    "privileged_groups = [{'sex': 1.0}]\n",
    "unprivileged_groups = [{'sex': 0.0}]\n",
    "pp_ = LFR(unprivileged_groups=unprivileged_groups,\n",
    "         privileged_groups=privileged_groups,\n",
    "         k=10, Ax=0.1, Ay=1.0, Az=2.0,\n",
    "         verbose=1\n",
    "        )\n",
    "dataset_orig_train_m = pp_.fit_transform(dataset_orig_train)\n",
    "y = deepcopy(dataset_orig_test.labels)\n",
    "dataset_orig_test_m = pp_.transform(dataset_orig_test)\n",
    "model = LogisticRegression()\n",
    "model = model.fit(dataset_orig_train_m.features, dataset_orig_train_m.labels.ravel())\n",
    "y_pred = model.predict(dataset_orig_test_m.features)\n",
    "accuracy_score(y_pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print((dataset_orig_test.labels == y).all())\n",
    "print(dataset_orig_test.labels is y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    9],\n",
       "       [   10],\n",
       "       [   11],\n",
       "       ...,\n",
       "       [14646],\n",
       "       [14647],\n",
       "       [14648]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "np.argwhere(dataset_orig_test.labels != y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "notebook.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
